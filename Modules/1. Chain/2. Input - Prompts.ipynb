{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Template\n",
    "最基本的用法極度類似 Python 的 String formatting，幫助開發者簡便地寫出格式一樣但內容不同的 prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 LLM 用 Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1: 空條承太郎的替身是白金之星。\n",
      "Prompt 2: 喬瑟夫·喬斯達的替身是隱者之紫。\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"person\", \"spirit\"], template=\"{person}的替身是{spirit}。\"\n",
    ")\n",
    "\n",
    "prompt1 = prompt_template.format(person=\"空條承太郎\", spirit=\"白金之星\")\n",
    "print(\"Prompt 1:\", prompt1)\n",
    "\n",
    "prompt2 = prompt_template.format(person=\"喬瑟夫·喬斯達\", spirit=\"隱者之紫\")\n",
    "print(\"Prompt 2:\", prompt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Chat Model 用 Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當使用 Chat Model 時，最好是使用 `ChatTemplate`。因為 Chat Model 如之前所介紹的，是有針對對話紀錄優化過的模型，因此利用 `ChatTemplate` 將內容轉化成對話紀錄的形式，理論上來說對對話對話模型來說是最好的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是一個喜歡玩捉迷藏的小孩'),\n",
      " HumanMessage(content='藏好了嗎?'),\n",
      " AIMessage(content='藏好了~'),\n",
      " HumanMessage(content='面麻，找到你了!')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pprint import pprint\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "   [ (\"system\", \"你是一個喜歡玩捉迷藏的小孩\"), \n",
    "     (\"human\", \"藏好了嗎?\"),\n",
    "     (\"ai\", \"藏好了~\"),\n",
    "     (\"human\", \"{name}，找到你了!\"), \n",
    "  ]\n",
    ")\n",
    "\n",
    "pprint(prompt_template.format_messages(name=\"面麻\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若沒有甚麼角色間對話的問題，也可以用單純的文字 (text) 來建立對話模板 (ChatPrompteTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='請依照下面的資訊「你的社團學長倒了一杯水」來回答問題「這杯水可以燃燒嗎?」')]\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template('請依照下面的資訊「{context}」來回答問題「{question}」')\n",
    "pprint(prompt_template.format_messages(context=\"你的社團學長倒了一杯水\", question=\"這杯水可以燃燒嗎?\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. In-Context Learning\n",
    "Langchain 也提供了面向 In-Context Learning 的 Template, 方便我們舉例和挑選例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一個在新宿的廢棄大樓營業的占卜師。\n",
      "\n",
      "請告訴我 Richard 喜歡吃什麼樣的麵。答案：牛肉麵\n",
      "\n",
      "請告訴我 Kris 喜歡吃什麼樣的便當。答案：港式燒臘\n",
      "\n",
      "請告訴我 Sherry 喜歡吃什麼樣的甜點。答案：\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict\n",
    "import numpy as np\n",
    "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "icl_template = FewShotPromptTemplate(\n",
    "    prefix=\"你是一個在新宿的廢棄大樓營業的占卜師。\",\n",
    "    example_prompt=PromptTemplate(\n",
    "        input_variables=[\"person\", \"cuisine\", \"answer\"],\n",
    "        template=\"請告訴我 {person} 喜歡吃什麼樣的{cuisine}。答案：{answer}\",\n",
    "    ),\n",
    "    examples=[\n",
    "        {\"person\": \"Richard\", \"cuisine\": \"麵\", \"answer\": \"牛肉麵\"},\n",
    "        {\"person\": \"Kris\", \"cuisine\": \"便當\", \"answer\": \"港式燒臘\"},\n",
    "    ],\n",
    "    example_separator=\"\\n\\n\",\n",
    "    suffix=\"請告訴我 {person} 喜歡吃什麼樣的{cuisine}。答案：\",\n",
    "    input_variables=[\"person\", \"cuisine\"],\n",
    ")\n",
    "\n",
    "prompt_icl = icl_template.format(person=\"Sherry\", cuisine=\"甜點\")\n",
    "print(prompt_icl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當我們需要從很多的 examples 裡面挑選時，我們可以用 example selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icl_prompt1:\n",
      "你是一個在新宿的廢棄大樓營業的占卜師。\n",
      "\n",
      "請告訴我 Sheng 喜歡吃什麼樣的飲料。答案：珍珠奶茶\n",
      "\n",
      "請告訴我 Kris 喜歡吃什麼樣的便當。答案：港式燒臘\n",
      "\n",
      "請告訴我 Sherry 喜歡吃什麼樣的甜點。答案：\n",
      "\n",
      "========================\n",
      "\n",
      "icl_prompt2:\n",
      "你是一個在新宿的廢棄大樓營業的占卜師。\n",
      "\n",
      "請告訴我 Richard 喜歡吃什麼樣的麵。答案：牛肉麵\n",
      "\n",
      "請告訴我 Sheng 喜歡吃什麼樣的飲料。答案：珍珠奶茶\n",
      "\n",
      "請告訴我 Sara 喜歡吃什麼樣的壽司。答案：\n"
     ]
    }
   ],
   "source": [
    "class RandomSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    # Need to be implemented\n",
    "    def add_example(self, example: Dict[str, str]) -> Any:\n",
    "        return self.examples.append(example)\n",
    "\n",
    "    # Need to be implemented\n",
    "    def select_examples(self, input_variables: dict[str, str]) -> list[dict]:\n",
    "        \"\"\"Select which examples to use based on the inputs.\"\"\"\n",
    "        return np.random.choice(self.examples, size=2, replace=False)\n",
    "\n",
    "\n",
    "icl_template.examples = None\n",
    "icl_template.example_selector = RandomSelector(\n",
    "    [\n",
    "        {\"person\": \"Richard\", \"cuisine\": \"麵\", \"answer\": \"牛肉麵\"},\n",
    "        {\"person\": \"Kris\", \"cuisine\": \"便當\", \"answer\": \"港式燒臘\"},\n",
    "        {\"person\": \"Sheng\", \"cuisine\": \"飲料\", \"answer\": \"珍珠奶茶\"},\n",
    "        {\"person\": \"Lifu\", \"cuisine\": \"餅乾\", \"answer\": \"品客\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "icl_prompt1 = icl_template.format(person=\"Sherry\", cuisine=\"甜點\")\n",
    "print(\"icl_prompt1:\")\n",
    "print(icl_prompt1)\n",
    "\n",
    "print(\"\\n========================\\n\")\n",
    "\n",
    "icl_prompt2 = icl_template.format(person=\"Sara\", cuisine=\"壽司\")\n",
    "print(\"icl_prompt2:\")\n",
    "print(icl_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 還有很多現成的 example selectors !!!\n",
    "from langchain.prompts.example_selector import (\n",
    "    LengthBasedExampleSelector,\n",
    "    MaxMarginalRelevanceExampleSelector,\n",
    "    SemanticSimilarityExampleSelector,\n",
    "    NGramOverlapExampleSelector,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
