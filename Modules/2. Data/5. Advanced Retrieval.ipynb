{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Query Rewrite\n",
    "透過將問題 (query) 改寫，提升文件抽取 (document retrieval) 的性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 MultiQuery\n",
    "面對下面兩個痛點：\n",
    "- 人類看起來 query 中的一小點措辭的改變，也可能會影響文件抽取的結果，導致需要嘗試不同的 query (prompt tuning)\n",
    "- embeddings 沒辦法完整地捕捉所有 query 中的意思"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們可以嘗試:\n",
    "1. 根據使用者的 query，產生多個關注不同面向的替代 query\n",
    "2. 依據各個 query 獨立抽取文件\n",
    "3. 將各個 query 抽取出的文件集合併並去重複 (unique union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_setup import ChatOpenAI, pprint_documents, tracing_v2_enabled_if_api_key_set\n",
    "\n",
    "# 讀取資料\n",
    "loader = NotionDirectoryLoader(\"../../data/notion/\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 分割文件 (Document)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# VectorDB\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Qdrant.from_documents(documents=splits, embedding=embedding, location=\":memory:\")\n",
    "\n",
    "# 建立 MultiQueryRetriever\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectordb.as_retriever(search_kwargs={'k': 2}), llm=llm\n",
    ")\n",
    "\n",
    "# 紀錄 (logging) 內部產生的問題 (queries)\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. 隕石落下式開發法的定義是什麼？', '2. 隕石落下式開發法有哪些特點？', '3. 隕石落下式開發法如何應用在實際開發中？']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "今天來介紹日本最具代表性的軟體開發手法\n",
      "它的名子為 **隕石落下型開發**。\n",
      "\n",
      "# 第一節\n",
      "\n",
      "通常的**瀑布式開發**是像下面這樣的形式:\n",
      "| 步驟 | 內容     | 負責人     |\n",
      "| ---- | -------- | ---------- |\n",
      "| 1    | 要件定義 | Producer   |\n",
      "| 2    | 基本設計 | Director   |\n",
      "| 3    | 詳細設計 | Planner    |\n",
      "| 4    | 實裝     | Programmer |\n",
      "\n",
      "Metadata:{'source': '..\\\\..\\\\data\\\\notion\\\\隕石落下式開發法.md'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "而**隕石式開發**是像下面這樣子的形式：\n",
      "|     | 步驟 | 內容     | 負責人     |\n",
      "| --- | ---- | -------- | ---------- |\n",
      "| 神  | 1    | 要件定義 | Producer   |\n",
      "| 神  | 2    | 基本設計 | Director   |\n",
      "| 神  | 3    | 詳細設計 | Planner    |\n",
      "| 神  | 4    | 實裝     | Programmer |\n",
      "\n",
      "然後就會這樣（全部都被隕石砸到爆炸）：\n",
      "\n",
      "Metadata:{'source': '..\\\\..\\\\data\\\\notion\\\\隕石落下式開發法.md'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "然後就會這樣（全部都被隕石砸到爆炸）：\n",
      "\n",
      "💥要件定義💥Producer💥基本設計💥Director💥詳細設計💥Planner💥實裝💥Programmer\n",
      "\n",
      "這是敏捷式開法守法的循環\n",
      "\n",
      "[要件定義->基本設計->詳細設計->實裝]->[要件定義->基本設計->詳細設計->實裝]->\n",
      "\n",
      "但在神的面前都是無力的（全部都被隕石砸到爆炸）\n",
      "\n",
      "[要件💥定義-💥>基本設計💥->詳細設💥計->實💥裝]<->[要件定💥義->基本設💥計->詳💥細設💥計->💥實裝]->\n",
      "\n",
      "在神的一聲令下全部都會**崩壞**，\n",
      "\n",
      "而人民會努力地**重建**，\n",
      "\n",
      "這就是 -- 隕石落下式開發法。\n",
      "\n",
      "# 第二節\n",
      "\n",
      "Metadata:{'source': '..\\\\..\\\\data\\\\notion\\\\隕石落下式開發法.md'}\n",
      "[LangSmith URL]: https://smith.langchain.com/o/34ec837d-8405-462d-b949-fdfaebda792b/projects/p/fdcbda35-4d3a-418b-ab49-7e3205e630a6/r/4778c024-0c42-45e4-bc0a-e210e20a9404?poll=true\n"
     ]
    }
   ],
   "source": [
    "with tracing_v2_enabled_if_api_key_set(project_name='tutorial'):\n",
    "    question = \"什麼是隕石落下式開發法?\"\n",
    "    unique_docs = retriever_from_llm.get_relevant_documents(query=question)\n",
    "    pprint_documents(unique_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Self-querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當遇到使用者問題 (query) 隱含了針對詮釋資料 (metadata) 的條件時"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "from langchain.retrievers.self_query.chroma import ChromaTranslator\n",
    "from langchain.chains.query_constructor.base import (\n",
    "    load_query_constructor_chain,\n",
    "    DEFAULT_EXAMPLES\n",
    ")\n",
    "\n",
    "from langchain_setup import OpenAI, pprint_documents, tracing_v2_enabled_if_api_key_set\n",
    "\n",
    "# 文件 (documents)\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
    "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
    "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
    "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
    "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Toys come alive and have a blast doing so\",\n",
    "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
    "        metadata={\n",
    "            \"year\": 1979,\n",
    "            \"rating\": 9.9,\n",
    "            \"director\": \"Andrei Tarkovsky\",\n",
    "            \"genre\": \"science fiction\",\n",
    "            \"rating\": 9.9,\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 建立 Vectorstore\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Qdrant.from_documents(docs, embeddings, location=\":memory:\")\n",
    "\n",
    "# This example specifies a query and composite filter\n",
    "query = \"What's a movie after 1990 but before 2005 that's all about toys, and preferably is animated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LangSmith URL]: https://smith.langchain.com/o/34ec837d-8405-462d-b949-fdfaebda792b/projects/p/fdcbda35-4d3a-418b-ab49-7e3205e630a6/r/acd95022-aca8-4dc9-93a4-964ba5c59103?poll=true\n",
      "Document 1:\n",
      "\n",
      "Toys come alive and have a blast doing so\n",
      "\n",
      "Metadata:{'genre': 'animated', 'year': 1995}\n"
     ]
    }
   ],
   "source": [
    "# 定義詮釋資料 (metadata)的每一個欄位 (field)\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        description=\"The genre of the movie\",\n",
    "        type=\"string or list[string]\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"The year the movie was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"director\",\n",
    "        description=\"The name of the movie director\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 建立 SelfQueryRetriever\n",
    "llm = OpenAI(temperature=0)\n",
    "document_content_description = \"Brief summary of a movie\"\n",
    "selfq_retriever = SelfQueryRetriever.from_llm(\n",
    "    llm, vectorstore, document_content_description, metadata_field_info, verbose=True\n",
    ")\n",
    "\n",
    "# 實際抽取 (retrieve) 看看\n",
    "with tracing_v2_enabled_if_api_key_set(project_name='tutorial'):\n",
    "    selfq_retrieved_documents = selfq_retriever.get_relevant_documents(query)\n",
    "pprint_documents(selfq_retrieved_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這功能由一個複雜的 prompt 來實現，這個 prompt 依序提供了大語言模型 (LLM) 以下的資訊\n",
    "- 目標：將使用者問題結構化來對齊提供的資料格式\n",
    "- 輸出格式說明 (formatting instruction)\n",
    "- 解釋有哪些比較計算子 (comparison operators) 如等於、大於，哪些邏輯運算子 (logical operators) 如 and、or 可以用，還有怎麼使用\n",
    "- 數個範例，每個範例包含\n",
    "    - 資料內容的簡短說明\n",
    "    - 詮釋資料 (metadata) 欄位 (field) 的介紹\n",
    "    - 使用者問題 (user query)\n",
    "    - 模型產出的結構化的回答\n",
    "\n",
    "而建構這個複雜的 prompt ，除了我們提供的文件內容 (document content) 的說明 `document_content_description` 和詮釋資料 (metadata) 的說明 `metadata_field_info`，Langchain 自動提供了範例和能配合 vector store 的運算子 (operators) 的資訊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your goal is to structure the user's query to match the request schema provided below.\n",
      "\n",
      "<< Structured Request Schema >>\n",
      "When responding use a markdown code snippet with a JSON object formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"query\": string \\ text string to compare to document contents\n",
      "    \"filter\": string \\ logical condition statement for filtering documents\n",
      "}\n",
      "```\n",
      "\n",
      "The query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\n",
      "\n",
      "A logical condition statement is composed of one or more comparison and logical operation statements.\n",
      "\n",
      "A comparison statement takes the form: `comp(attr, val)`:\n",
      "- `comp` (and | or): comparator\n",
      "- `attr` (string):  name of attribute to apply the comparison to\n",
      "- `val` (string): is the comparison value\n",
      "\n",
      "A logical operation statement takes the form `op(statement1, statement2, ...)`:\n",
      "- `op` (and | or): logical operator\n",
      "- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\n",
      "\n",
      "Make sure that you only use the comparators and logical operators listed above and no others.\n",
      "Make sure that filters only refer to attributes that exist in the data source.\n",
      "Make sure that filters only use the attributed names with its function names if there are functions applied on them.\n",
      "Make sure that filters only use format `YYYY-MM-DD` when handling timestamp data typed values.\n",
      "Make sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\n",
      "Make sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.\n",
      "\n",
      "<< Example 1. >>\n",
      "Data Source:\n",
      "```json\n",
      "{\n",
      "    \"content\": \"Lyrics of a song\",\n",
      "    \"attributes\": {\n",
      "        \"artist\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Name of the song artist\"\n",
      "        },\n",
      "        \"length\": {\n",
      "            \"type\": \"integer\",\n",
      "            \"description\": \"Length of the song in seconds\"\n",
      "        },\n",
      "        \"genre\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "User Query:\n",
      "What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre\n",
      "\n",
      "Structured Request:\n",
      "```json\n",
      "{\n",
      "    \"query\": \"teenager love\",\n",
      "    \"filter\": \"and(or(eq(\\\"artist\\\", \\\"Taylor Swift\\\"), eq(\\\"artist\\\", \\\"Katy Perry\\\")), lt(\\\"length\\\", 180), eq(\\\"genre\\\", \\\"pop\\\"))\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "<< Example 2. >>\n",
      "Data Source:\n",
      "```json\n",
      "{\n",
      "    \"content\": \"Lyrics of a song\",\n",
      "    \"attributes\": {\n",
      "        \"artist\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Name of the song artist\"\n",
      "        },\n",
      "        \"length\": {\n",
      "            \"type\": \"integer\",\n",
      "            \"description\": \"Length of the song in seconds\"\n",
      "        },\n",
      "        \"genre\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "User Query:\n",
      "What are songs that were not published on Spotify\n",
      "\n",
      "Structured Request:\n",
      "```json\n",
      "{\n",
      "    \"query\": \"\",\n",
      "    \"filter\": \"NO_FILTER\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "<< Example 3. >>\n",
      "Data Source:\n",
      "```json\n",
      "{\n",
      "    \"content\": \"Brief summary of a movie\",\n",
      "    \"attributes\": {\n",
      "    \"genre\": {\n",
      "        \"description\": \"The genre of the movie\",\n",
      "        \"type\": \"string or list[string]\"\n",
      "    },\n",
      "    \"year\": {\n",
      "        \"description\": \"The year the movie was released\",\n",
      "        \"type\": \"integer\"\n",
      "    },\n",
      "    \"director\": {\n",
      "        \"description\": \"The name of the movie director\",\n",
      "        \"type\": \"string\"\n",
      "    },\n",
      "    \"rating\": {\n",
      "        \"description\": \"A 1-10 rating for the movie\",\n",
      "        \"type\": \"float\"\n",
      "    }\n",
      "}\n",
      "}\n",
      "```\n",
      "\n",
      "User Query:\n",
      "What's a movie after 1990 but before 2005 that's all about toys, and preferably is animated\n",
      "\n",
      "Structured Request:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chain = load_query_constructor_chain(\n",
    "    llm=llm,\n",
    "    document_contents=document_content_description,\n",
    "    attribute_info=metadata_field_info,\n",
    "    # 例子是 Langchain 預先提供的\n",
    "    examples=DEFAULT_EXAMPLES,\n",
    "    # 使用所選擇的 vectoreDB 所支援的，詮釋資料 (metatdat) 篩選 (filter) 用的運算子 (operators)\n",
    "    allowed_comparators=ChromaTranslator.allowed_operators,\n",
    "    allowed_operators=ChromaTranslator.allowed_operators,\n",
    ")\n",
    "print(chain.prompt.format(query=query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiVector\n",
    "我們想要將文件 (document) 的內容完整地傳給大語言模型 (LLM)，但是這個文件內容因為某些原因（例如包含的資訊太多太雜）而不利於 embedding-based retrieval。\n",
    "\n",
    "或是不想更改文件本身內容，但又想提升文件抽取 (document retrieval) 的準度的時候可以怎麼辦？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain 實作並介紹了以下三種作法\n",
    "- 分塊 (chunking)\n",
    "- 摘要 (summarization): 對文件進行摘要，並將摘要的 embedding 和/取代 文件的 embedding 作為該文件的對應\n",
    "- 虛擬命令/問題 (hypothetical queries): 生成適合該文件回答的問題，並將該問題的 embedding 或該問題加文件的 embedding 作為對應。\n",
    "\n",
    "這些作法的共通思維是：針對源文件(source document)衍生出能夠對應到該文件的某些衍生物(derivatives)，而這些衍生物會取代或跟著源文件一起成為抽取的候選，若選到某個衍生物，則會追循其對應抽取出其對應的整份源文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "太長或太雜的文件會導致細部語義會彼此稀釋。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "某大學的研究室發現，世界上至少有16%部手機上是沾有糞便等排洩物的。\n",
      "\n",
      "原子如果沒有了空隙的話，那麼全世界的人類可能會被擠壓到蘋果那麼大的空間。\n",
      "\n",
      "Metadata:{}\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain_setup import pprint_documents, pprint\n",
    "from langchain_setup.qdrant import pprint_qdrant_documents\n",
    "\n",
    "# 文件\n",
    "doc = \"\"\"\\\n",
    "人口密度大的地鐵里，空氣中的至少有15%包含著每個人的皮膚。\n",
    "\n",
    "其實貓咪其實也和人類一樣，是分左撇子和右撇子的，不過兩者數量差不多，大家可以關注一下身邊的喵星人，可能會發現它們習慣用哪一隻爪子，就知道它們到底是左撇子還是右撇子了。\n",
    "\n",
    "-----\n",
    "\n",
    "某大學的研究室發現，世界上至少有16%部手機上是沾有糞便等排洩物的。\n",
    "\n",
    "原子如果沒有了空隙的話，那麼全世界的人類可能會被擠壓到蘋果那麼大的空間。\n",
    "\"\"\"\n",
    "documents = [Document(page_content=doc)]\n",
    "\n",
    "# 切割文件 (document splitting)\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, chunk_overlap=0, separators=[\"-----\"], keep_separator=False\n",
    ")\n",
    "_documents = splitter.split_documents(documents)\n",
    "\n",
    "# 建立 retriever\n",
    "retriever = Qdrant.from_documents(\n",
    "    _documents, OpenAIEmbeddings(), location=\":memory:\"\n",
    ").as_retriever(search_kwargs={\"k\": 1})\n",
    "pprint_documents(retriever.get_relevant_documents(\"貓咪被擠壓到蘋果大的空間時會用哪隻手清理糞便等排泄物？\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "切分文件 (parent document) 並讓各切分 (child document) 的 embedding 也都對應到該文件 (parent document)。\n",
    "\n",
    "使得文件能夠對應到更細部的語義，但同時又能夠對應到整份文件而非部分文件給下一步驟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "人口密度大的地鐵里，空氣中的至少有15%包含著每個人的皮膚。\n",
      "\n",
      "其實貓咪其實也和人類一樣，是分左撇子和右撇子的，不過兩者數量差不多，大家可以關注一下身邊的喵星人，可能會發現它們習慣用哪一隻爪子，就知道它們到底是左撇子還是右撇子了。\n",
      "\n",
      "\n",
      "\n",
      "Metadata:{}\n"
     ]
    }
   ],
   "source": [
    "# 親分割器 (parent splitter) 負責從原生文件 (raw documents) 切出親文件 (parent documents)\n",
    "# parent documents 是我們要傳給大語言模型 (LLM) 的\n",
    "# parent splitter 最重要的任務之一是符合大語言模型的可處理長度或可有效處理的長度\n",
    "parent_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, chunk_overlap=0, separators=[\"-----\"], keep_separator=False\n",
    ")\n",
    "\n",
    "# 子分割器 (child splitter) 負責再從每個親文件中各自切出更小的子文件 (child documents)\n",
    "# 子分割器的任務是要切出適合 embedding-based retrieval 的片段\n",
    "# 通常會希望該片段內同質性高少雜訊或不會太長\n",
    "child_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50, chunk_overlap=0, separators=[\"\\n\\n\"], keep_separator=False\n",
    ")\n",
    "\n",
    "# Empty Vectore store\n",
    "vectorstore = Qdrant.from_texts(\n",
    "    [\"dummy\"], embedding=OpenAIEmbeddings(), location=\":memory:\"\n",
    ")  #\n",
    "vectorstore.delete(\n",
    "    [vectorstore.client.scroll(vectorstore.collection_name)[0][0].id]\n",
    ")  # delete dummy\n",
    "\n",
    "# ParentDocumentRetriever\n",
    "chunk_retriever = ParentDocumentRetriever(\n",
    "    # vectore 會拿來儲存子文件和其 embeddings\n",
    "    vectorstore=vectorstore,\n",
    "    # docstore 會儲存親文件\n",
    "    docstore=InMemoryStore(),\n",
    "    # 把 splitter 給 retriever 讓 retriever 在新增文件時幫忙切\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,  # 不給也是可以的，會直接把傳入的文件 (documents) 做為親文件 (parent documents)\n",
    "    # 只取最相關的一個文件\n",
    "    search_kwargs={\"k\": 1},\n",
    ")\n",
    "\n",
    "# 實際看看這樣細分的方法能不能幫助我們抽取到正確相關的文件\n",
    "chunk_retriever.add_documents(\n",
    "    documents\n",
    ")  # 把原生文件 (raw documents) 丟進去給 `ParentDocumentRetriever` 切分和處理\n",
    "retrieved_documents = chunk_retriever.get_relevant_documents(\"貓咪被擠壓到蘋果大的空間時會用哪隻手清理糞便等排泄物？\")\n",
    "pprint_documents(retrieved_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們可以看到 vectorstore 儲存了子文件 (child document) 對應的親文件 (parent document) 的識別碼 (id)\n",
    "\n",
    "而 docstore 則儲存親文件 (parent documents) 和其識別碼 (ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VECTOR STORE\n",
      "\n",
      "Document 63d5171a5e8e4d2db8f93ab8b36a9bdf:\n",
      "\n",
      "原子如果沒有了空隙的話，那麼全世界的人類可能會被擠壓到蘋果那麼大的空間。\n",
      "\n",
      "Metadata:{'doc_id': 'f63569e1-a7a8-40ad-aaac-fe3116edce4b'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6849b0c9f22f421dbe8f1483bc3298a6:\n",
      "\n",
      "某大學的研究室發現，世界上至少有16%部手機上是沾有糞便等排洩物的。\n",
      "\n",
      "Metadata:{'doc_id': 'f63569e1-a7a8-40ad-aaac-fe3116edce4b'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 7424ec0f04f146dba2edc81f6e81edc7:\n",
      "\n",
      "人口密度大的地鐵里，空氣中的至少有15%包含著每個人的皮膚。\n",
      "\n",
      "Metadata:{'doc_id': '95c8b6fb-5154-46f8-8138-5c9fdb777b6b'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document bc112bc738204db4a62b49adea73ee50:\n",
      "\n",
      "其實貓咪其實也和人類一樣，是分左撇子和右撇子的，不過兩者數量差不多，大家可以關注一下身邊的喵星人，可能會發現它們習慣用哪一隻爪子，就知道它們到底是左撇子還是右撇子了。\n",
      "\n",
      "Metadata:{'doc_id': '95c8b6fb-5154-46f8-8138-5c9fdb777b6b'}\n",
      "DOCSTORE\n",
      "\n",
      "{'store': {'95c8b6fb-5154-46f8-8138-5c9fdb777b6b': Document(page_content='人口密度大的地鐵里，空氣中的至少有15%包含著每個人的皮膚。\\n\\n其實貓咪其實也和人類一樣，是分左撇子和右撇子的，不過兩者數量差不多，大家可以關注一下身邊的喵星人，可能會發現它們習慣用哪一隻爪子，就知道它們到底是左撇子還是右撇子了。\\n\\n'),\n",
      "           'f63569e1-a7a8-40ad-aaac-fe3116edce4b': Document(page_content='某大學的研究室發現，世界上至少有16%部手機上是沾有糞便等排洩物的。\\n\\n原子如果沒有了空隙的話，那麼全世界的人類可能會被擠壓到蘋果那麼大的空間。')}}\n"
     ]
    }
   ],
   "source": [
    "print(\"VECTOR STORE\", end=\"\\n\\n\")\n",
    "pprint_qdrant_documents(vectorstore)\n",
    "print(\"DOCSTORE\", end=\"\\n\\n\")\n",
    "pprint(chunk_retriever.docstore.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "當文章本身非常長或資訊非常雜，embedding 會雜質很多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import attrgetter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.document import Document\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import MultiVectorRetriever\n",
    "from langchain_setup import ChatOpenAI, pprint_documents\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"比黑色更黑，比黑暗更暗的漆黑，在此寄託吾真紅的金光吧！覺醒之時的到來，荒謬至極的墮落章理，成為無形的扭曲而顯現吧！起舞吧，起舞吧，起舞吧！吾之力量本源之愿的崩壞，無人可及的崩壞，將天地萬象焚燒殆盡，自深淵降臨吧，這就是人類最強威力的攻擊手段，這就是究極攻擊魔法，Explosion!\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們可以透過重點整理來精煉 embedding，使 embedding-based retrieval 更準"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "比黑色更黑，比黑暗更暗的漆黑，在此寄託吾真紅的金光吧！覺醒之時的到來，荒謬至極的墮落章理，成為無形的扭曲而顯現吧！起舞吧，起舞吧，起舞吧！吾之力量本源之愿的崩壞，無人可及的崩壞，將天地萬象焚燒殆盡，自深淵降臨吧，這就是人類最強威力的攻擊手段，這就是究極攻擊魔法，Explosion!\n",
      "\n",
      "Metadata:{}\n"
     ]
    }
   ],
   "source": [
    "# 從源文件 (source documents) 產生衍生物 (derivatives)\n",
    "chain = (\n",
    "    {\"doc\": attrgetter(\"page_content\")}\n",
    "    | ChatPromptTemplate.from_template(\"請用一句話摘要下列的資訊:\\n\\n{doc}\")\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "summaries = chain.batch(documents)  # 平行化處理\n",
    "\n",
    "# 標注源文件和衍生物的對應\n",
    "child_documents = []\n",
    "document_ids = []\n",
    "for i, (summary, document) in enumerate(zip(summaries, documents)):\n",
    "    document_id = str(i)\n",
    "    child_document = Document(page_content=summary, metadata={\"doc_id\": document_id})\n",
    "    child_documents.append(child_document)\n",
    "    document_ids.append(document_id)\n",
    "\n",
    "# 衍生物存入 vectorestore\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=child_documents, embedding=OpenAIEmbeddings(), location=\":memory:\"\n",
    ")\n",
    "\n",
    "# [Optional] 將源文件也存入 vectorstore\n",
    "_documents = []\n",
    "for document_id, document in zip(document_ids, documents):\n",
    "    _document = Document(\n",
    "        page_content=document.page_content, metadata={\"doc_id\": document_id}\n",
    "    )\n",
    "    _documents.append(_document)\n",
    "vectorstore.add_documents(documents=_documents)\n",
    "\n",
    "# 儲存源文件 (source documents) 及其識別 (id)\n",
    "docstore = InMemoryStore()\n",
    "docstore.mset(list(zip(document_ids, documents)))\n",
    "\n",
    "# 建立 MultiVectorRetriever\n",
    "summary_retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=docstore,\n",
    "    id_key=\"doc_id\",\n",
    ")\n",
    "\n",
    "# 試著抽取看看\n",
    "retrieved_docs = summary_retriever.get_relevant_documents(\"什麼魔法會將一切燃燒殆盡？\")\n",
    "pprint_documents(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其實真正透過 embedding-based retrieval 選到的是其衍生物"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='使用最強的攻擊魔法\"Explosion\"，將一切燃燒殆盡。', metadata={'doc_id': '0'})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_retriever.vectorstore.similarity_search(query=\"什麼魔法會將一切焚燒殆盡？\", k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothetical Queries\n",
    "當我們在找資料時會看有沒有其他人問過類似的問題，而在文件抽取（document retrieval）中我們也可以實踐這個思路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import attrgetter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.document import Document\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.retrievers import MultiVectorRetriever\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "from langchain.chains.openai_functions.base import convert_to_openai_function\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_setup import ChatOpenAI, pprint_documents\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"比黑色更黑，比黑暗更暗的漆黑，在此寄託吾真紅的金光吧！覺醒之時的到來，荒謬至極的墮落章理，成為無形的扭曲而顯現吧！起舞吧，起舞吧，起舞吧！吾之力量本源之愿的崩壞，無人可及的崩壞，將天地萬象焚燒殆盡，自深淵降臨吧，這就是人類最強威力的攻擊手段，這就是究極攻擊魔法，Explosion!\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們讓大語言模型 (LLM) 根據文件 (document) 內容自動產生問句 (queries)，以這些問句作為該文件的衍生物 (derivatives)，抽取到這些問題就回傳其對應的源文件 (source document)。這個方法有幾個好處\n",
    "1. 每個問題可能可以代表內容不同的面向或措辭\n",
    "2. 除了自動產生的問題外，也可以手動將失敗的問題 (query) 對應到正確的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='比黑色更黑，比黑暗更暗的漆黑，在此寄託吾真紅的金光吧！覺醒之時的到來，荒謬至極的墮落章理，成為無形的扭曲而顯現吧！起舞吧，起舞吧，起舞吧！吾之力量本源之愿的崩壞，無人可及的崩壞，將天地萬象焚燒殆盡，自深淵降臨吧，這就是人類最強威力的攻擊手段，這就是究極攻擊魔法，Explosion!')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 從源文件 (source documents) 產生衍生物 (derivatives)\n",
    "class hypothetical_questions(BaseModel):\n",
    "    \"\"\"Generate hypothetical questions\"\"\"\n",
    "\n",
    "    questions: list[str]\n",
    "\n",
    "\n",
    "function = convert_to_openai_function(hypothetical_questions)\n",
    "\n",
    "query_gen_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    | ChatPromptTemplate.from_template(\"請產生三個可以根據以下的資訊回答的問題:\\n\\n{doc}\")  # 可以設定更多個\n",
    "    # 在這邊為了教學將溫度 (temperature) 設為零，但實際上增加一些隨機性會比較好\n",
    "    | ChatOpenAI(temperature=0).bind(\n",
    "        functions=[function], function_call={\"name\": \"hypothetical_questions\"}\n",
    "    )\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"questions\")\n",
    ")\n",
    "questions = query_gen_chain.batch(documents)\n",
    "\n",
    "# 標注源文件和衍生物的對應\n",
    "child_documents = []\n",
    "document_ids = []\n",
    "for i, (_questions, document) in enumerate(zip(questions, documents)):\n",
    "    document_id = str(i)\n",
    "    for question in _questions:\n",
    "        child_document = Document(\n",
    "            page_content=question, metadata={\"doc_id\": document_id}\n",
    "        )\n",
    "        child_documents.append(child_document)\n",
    "    document_ids.append(document_id)\n",
    "\n",
    "# 衍生物存入 vectorestore\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=child_documents, embedding=OpenAIEmbeddings(), location=\":memory:\"\n",
    ")\n",
    "\n",
    "# [Optional] 將源文件也存入 vectorstore\n",
    "_documents = []\n",
    "for document_id, document in zip(document_ids, documents):\n",
    "    _document = Document(\n",
    "        page_content=document.page_content, metadata={\"doc_id\": document_id}\n",
    "    )\n",
    "    _documents.append(_document)\n",
    "vectorstore.add_documents(documents=_documents)\n",
    "\n",
    "# 儲存源文件 (source documents) 及其識別 (id)\n",
    "docstore = store = InMemoryStore()\n",
    "docstore.mset(list(zip(document_ids, documents)))\n",
    "\n",
    "# 建立 MultiVectorRetriever\n",
    "hypothetical_questions_retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=docstore,\n",
    "    id_key=\"doc_id\",\n",
    ")\n",
    "\n",
    "# 試著抽取看看\n",
    "hypothetical_questions_retriever.get_relevant_documents(\"什麼魔法是人類最強的攻擊？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其實真正透過 embedding-based retrieval 選到的是其衍生物"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['什麼顏色比黑色更黑？', '什麼比黑暗更暗？', '什麼是人類最強威力的攻擊手段？']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='什麼是人類最強威力的攻擊手段？', metadata={'doc_id': '0'})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(questions)\n",
    "\n",
    "hypothetical_questions_retriever.vectorstore.similarity_search(\n",
    "    query=\"什麼魔法是人類最強的攻擊？\", k=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**想想看**: MultiQuery 是從使用者問句 (user query)，改寫成多個問句。Hypothetical queries 則是從文件出發，設計不同的問句。這兩個方法間在能達成的效果上有何不同？什麼情況下用哪個比較好？可以合併一起用嗎？\n",
    "<details>\n",
    "<summary>參考</summary>\n",
    "當使用者問句非常複雜且隱含複數條件或要求時，可以利用MultiQuery 將其拆解成數個比較單純的 query。hypothetical queries 則可以當作是某種拆解複雜文件資訊成不同的單純面向的方法。另外個人認為兩種方法都可以達到減少因為措辭差異而對應不到的問題。兩者其實不是只能使用一種，合併使用是可能的。\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeWeightedVectorStoreRetriever\n",
    "\n",
    "`recency_score = semantic_similarity + (1.0 - decay_rate) ^ hours_passed_since_last_access`\n",
    "- 跟何時創建的檔案無關，就算是很以前的檔案，只要最近有被抽取到，就是新鮮的\n",
    "- 會給每個文件自動標註上\n",
    "  - `last_accessed_at` (最後存取時間): 用於計算經過的時間\n",
    "  - `created_at` (創建時間): 沒有被用到，可能只是讓你參考用\n",
    "- `decay_rate` 越大，越久沒被碰的文件越不容易被碰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 08f4b87f627d43c6b6cc80a175712efd:\n",
      "\n",
      "昨天的風兒真是喧囂呢\n",
      "\n",
      "Metadata:\n",
      "{'buffer_idx': 0,\n",
      " 'created_at': datetime.datetime(2023, 11, 10, 18, 1, 27, 66934),\n",
      " 'last_accessed_at': datetime.datetime(2023, 11, 9, 18, 1, 27, 66934)}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6cc62d526e26428ab1ce29edf074fc4f:\n",
      "\n",
      "這個味道是說謊的味道\n",
      "\n",
      "Metadata:\n",
      "{'buffer_idx': 1,\n",
      " 'created_at': datetime.datetime(2023, 11, 10, 18, 1, 27, 313571),\n",
      " 'last_accessed_at': datetime.datetime(2023, 11, 10, 18, 1, 27, 313571)}\n",
      "\n",
      "=========== 抽取 (retrieval) 結果 ===========\n",
      "\n",
      "Document 1:\n",
      "\n",
      "這個味道是說謊的味道\n",
      "\n",
      "Metadata:\n",
      "{'buffer_idx': 1,\n",
      " 'created_at': datetime.datetime(2023, 11, 10, 18, 1, 27, 313571),\n",
      " 'last_accessed_at': datetime.datetime(2023, 11, 10, 18, 1, 28, 578207)}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain_setup import pprint_documents\n",
    "from langchain_setup.qdrant import create_inmemory_empty_qdrant, pprint_qdrant_documents\n",
    "\n",
    "# 以空的 vector store 來建立 retriever\n",
    "retriever = TimeWeightedVectorStoreRetriever(\n",
    "    vectorstore=create_inmemory_empty_qdrant(), decay_rate=0.999, k=1\n",
    ")\n",
    "\n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "# 最後存取時間 (last_accessed_at) 和 創建時間 (created_at) 可以手動設定\n",
    "retriever.add_documents(\n",
    "    [Document(page_content=\"昨天的風兒真是喧囂呢\", metadata={\"last_accessed_at\": yesterday})]\n",
    ")\n",
    "# 或是不設定的話就是兩個皆設為現在時間\n",
    "retriever.add_documents([Document(page_content=\"這個味道是說謊的味道\")])\n",
    "\n",
    "# 檢視 vector store 內部\n",
    "pprint_qdrant_documents(retriever.vectorstore)\n",
    "time.sleep(1)\n",
    "\n",
    "# 由於設定極高 decay rate ，抽取 (retrieve) 到過去取用 (access) 的文件的可能性極低\n",
    "# 被抽取的文件的最後存取時間會自動更新\n",
    "print(\"\\n=========== 抽取 (retrieval) 結果 ===========\\n\")\n",
    "pprint_documents(retriever.get_relevant_documents(\"風兒很喧囂\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "想想看:\n",
    "- 越久沒被碰的文件越被難抽取，在什麼樣的情況下會造成惡性循環?\n",
    "- 要怎麼實作用「檔案創建時間」或「檔案內容更新時間」來做 time decay ?\n",
    "\n",
    "<details>\n",
    "<summary>參考</summary>\n",
    "有用但是很少被用的文件，因少被抽取而被降低順序，因降低順位而被更少抽取\n",
    "\n",
    "可以嘗試手動將文件 (Document) 的 'last_accessed_at' 值設成我們想要的日期時間\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Retriever\n",
    "在介紹抽取器 (Retriever) 時我們提到了除了基於 embeddings 相似度以外的抽取器，而我們剛才也介紹過了許多進階的抽取器。每個抽取器都有不同的特性，我們是否可以結合不同的優勢來截長補短？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 並聯\n",
    "將從不同種類的抽取器所得到的相關性分數 (relevance score) 以使用者設定的權重 (weights) 結合，作為該文件 (document) 的最終相關性分數，並以該分數作為根據抽取 (retrieve)。\n",
    "\n",
    "這種方法雖然比較花成本，但是可能可以提高召回率 (recall)，也就是減少真的相關的文件 (document) 沒有被抽取到的機率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Ugh! Pen Pineapple Apple Pen\n",
      "\n",
      "Metadata:{}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Apple pen~\n",
      "\n",
      "Metadata:{}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Pineapple pen~\n",
      "\n",
      "Metadata:{}\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain_setup import pprint_documents\n",
    "\n",
    "doc_list = [\n",
    "    \"Apple pen~\",\n",
    "    \"Pineapple pen~\",\n",
    "    \"Ugh! Pen Pineapple Apple Pen\",\n",
    "]\n",
    "\n",
    "# 基於語面的抽取 (Lexical-based retrieval) (BM25)\n",
    "bm25_retriever = BM25Retriever.from_texts(doc_list)\n",
    "bm25_retriever.k = 2\n",
    "\n",
    "# 基於語義 embedding 的抽取 (Embedding-based retrieval)\n",
    "vectorstore = Qdrant.from_texts(doc_list, OpenAIEmbeddings(), location=\":memory:\")\n",
    "embedding_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# 組合 (ensemble) 兩種抽取器 (retriever)\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, embedding_retriever], weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "docs = ensemble_retriever.get_relevant_documents(\"apples\")\n",
    "pprint_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 串連\n",
    "多階段的（multi-staged）方法在建構搜尋系統中是常被使用到的方法。其會先用比較弱但比較快的排序 (ranking) 方法，配合比較寬鬆的相關度閥值 (threshold) 做大量篩選，再只把粗篩過後的結果傳給下一個更強但更慢的排序 (ranking) 方法做篩選或排序，然後可能再重複傳給下一個更強排序方法的過程。\n",
    "\n",
    "當文本 (documents) 數量很大時，這是一個可以同時顧及成本、精準度 (precision)、召回率 (recall) 的方法\n",
    "\n",
    "雖然 Langchain 沒有介紹串連的作法或現成的實作，但我們還是可以透過現有的東西拼湊出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\121664\\micromamba\\envs\\dev\\lib\\site-packages\\langchain\\chains\\llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "c:\\Users\\121664\\micromamba\\envs\\dev\\lib\\site-packages\\langchain\\chains\\llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "c:\\Users\\121664\\micromamba\\envs\\dev\\lib\\site-packages\\langchain\\chains\\llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Apple pen~\n",
      "\n",
      "Metadata:{}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Ugh! Pen Pineapple Apple Pen\n",
      "\n",
      "Metadata:{}\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain_setup import pprint_documents\n",
    "from langchain.retrievers.document_compressors import LLMChainFilter\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_setup import ChatOpenAI\n",
    "\n",
    "doc_list = [\n",
    "    \"天之鎖\",\n",
    "    \"修爾夏伽那\",\n",
    "    \"天地乖離開闢之星\",\n",
    "    \"王之號砲\",\n",
    "    \"黑帝斯的隱形頭盔\",\n",
    "    \"Apple pen~\",\n",
    "    \"Pineapple pen~\",\n",
    "    \"Ugh! Pen Pineapple Apple Pen\",\n",
    "]\n",
    "\n",
    "# 基於語義 embedding 的抽取 (Embedding-based retrieval) 配上一個相對寬鬆的篩選閥值 (threshold)\n",
    "vectorstore = Qdrant.from_texts(doc_list, OpenAIEmbeddings(), location=\":memory:\")\n",
    "embedding_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.75}\n",
    ")\n",
    "\n",
    "# 以大型語言模型 (LLM) 來直接同時比較兩篇文章的方法\n",
    "stronger_ranking = LLMChainFilter.from_llm(ChatOpenAI(temperature=0))\n",
    "\n",
    "# 串連\n",
    "cascade_retriever = ContextualCompressionRetriever(\n",
    "    base_retriever=embedding_retriever, base_compressor=stronger_ranking\n",
    ")\n",
    "\n",
    "docs = cascade_retriever.get_relevant_documents(\"apples\")\n",
    "pprint_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從下方例子可以看出，在第一階段時便已過濾掉明顯不相關的文件 (document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Apple pen~\n",
      "\n",
      "Metadata:{}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Ugh! Pen Pineapple Apple Pen\n",
      "\n",
      "Metadata:{}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Pineapple pen~\n",
      "\n",
      "Metadata:{}\n"
     ]
    }
   ],
   "source": [
    "embedding_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.75}\n",
    ")\n",
    "docs_after_1st_stage = embedding_retriever.get_relevant_documents('apples')\n",
    "pprint_documents(docs_after_1st_stage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**想想看** 偏早期階段 (stage) 排序 (ranking) 法跟偏後期的階段的排序法，目標是怎麼的不一樣？\n",
    "<details>\n",
    "<summary>參考</summary>\n",
    "前面的方法側重於在不要誤過濾掉相關文件的前提下 (重視 Recall)，如何快速而低成本過濾掉大部分的文件，減少傳給後面高成本排序法的文件的數量。越靠後面的方法則會越側重於給出準確的相關度排序 (重視 Precision)，只留下真的相關的文件或給出非常好的相關度排序。\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
